#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""ÃœrÃ¼n Scraper v4.0 - Temiz ve Basit"""

import requests
from bs4 import BeautifulSoup
import time
import re
from supabase import create_client
from datetime import datetime
from urllib.parse import urlparse
import hashlib

SUPABASE_URL = "https://zmmpuysxnwqngvlafolm.supabase.co"
SUPABASE_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InptbXB1eXN4bndxbmd2bGFmb2xtIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NjkwNjA0MTAsImV4cCI6MjA4NDYzNjQxMH0.4Q7k-cDcaGhOurMlofG8lkd4ApPyYexxkMdXxH-lI0k"

supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

# Site konfigÃ¼rasyonlarÄ±
SITE_CONFIGS = {
    'technopluskibris.com': {
        'name': 'TECHNOPLUSKIBRIS',
        'price_selectors': ['.product-price span', '.product-price', 'span[class*="price"]'],
        'title_selectors': ['h1.product-name', 'h1', 'title'],
        'currency': 'TL'
    },
    'durmazz.com': {
        'name': 'DURMAZZ',
        'price_selectors': ['span[itemprop="price"]', '.oe_currency_value', 'span.oe_price'],
        'title_selectors': ['h1[itemprop="name"]', 'h1', 'title'],
        'currency': 'USD'
    },
    'irismostore.com': {
        'name': 'IRISMOSTORE',
        'price_selectors': [
            'div.price-usd',  # â† Ä°ÅTE BURASI! div class="price-usd"
            '.price-usd',
            'div[class*="price-usd"]',
            '.usd-price-line div',
            'h3'
        ],
        'title_selectors': ['h1', 'title'],
        'currency': 'USD'
    },
    'sharafstore.com': {
        'name': 'SHARAFSTORE',
        'price_selectors': ['span.price', '.product-price span', 'span[class*="price"]'],
        'title_selectors': ['h1.product-title', 'h1', 'title'],
        'currency': 'TL'
    }
}

def get_all_urls():
    """productofsitemapcrawl tablosundan TÃœM URL'leri Ã§ek"""
    print("\nğŸ“¥ TÃ¼m URL'ler Ã§ekiliyor...")
    
    try:
        response = supabase.table('productofsitemapcrawl')\
            .select('id, url, anawebsite')\
            .execute()
        
        if response.data:
            print(f"  âœ… {len(response.data)} URL bulundu")
            return response.data
        else:
            print("  âš ï¸ HiÃ§ URL yok!")
            return []
    except Exception as e:
        print(f"  âŒ Hata: {e}")
        return []

def get_site_config(url):
    """URL'den site config'ini bul"""
    domain = urlparse(url).netloc.replace('www.', '')
    
    for config_domain, config in SITE_CONFIGS.items():
        if config_domain in domain:
            return config
    
    # Default
    return {
        'name': domain.upper(),
        'price_selectors': ['.price', 'span.price'],
        'title_selectors': ['h1', 'title'],
        'currency': 'TL'
    }

def extract_price(soup, selectors):
    """FiyatÄ± Ã§Ä±kar - basit ve etkili"""
    for selector in selectors:
        try:
            element = soup.select_one(selector)
            if not element:
                continue
            
            text = element.get_text(strip=True)
            if not text:
                continue
            
            # Sadece rakamlarÄ± al
            numbers = re.sub(r'[^\d.]', '', text)
            
            if numbers:
                price = float(numbers)
                if price > 0:
                    return price
        except:
            continue
    
    return None

def extract_title(soup, selectors):
    """BaÅŸlÄ±ÄŸÄ± Ã§Ä±kar"""
    for selector in selectors:
        try:
            element = soup.select_one(selector)
            if element:
                title = element.get_text(strip=True)
                if element.name == 'title':
                    title = title.split('|')[0].split('-')[0].strip()
                if title and len(title) > 3:
                    return title
        except:
            continue
    
    return "Bilinmiyor"

def generate_sku(url, site_name):
    """SKU oluÅŸtur"""
    url_part = url.rstrip('/').split('/')[-1][:30]
    site_prefix = site_name[:3].upper()
    url_hash = hashlib.md5(url.encode()).hexdigest()[:8]
    return f"{site_prefix}-{url_part}-{url_hash}"

def scrape_url(url, config):
    """Tek bir URL'yi scrape et"""
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        title = extract_title(soup, config['title_selectors'])
        price = extract_price(soup, config['price_selectors'])
        currency = config['currency']
        
        return {
            'title': title,
            'price': price,
            'currency': currency,
            'url': url,
            'site': config['name']
        }
    
    except Exception as e:
        print(f"      âœ— Hata: {str(e)[:50]}")
        return None

def save_to_db(product, site_name):
    """products tablosuna kaydet"""
    try:
        sku = generate_sku(product['url'], site_name)
        
        # Fiyat deÄŸiÅŸimi kontrolÃ¼
        existing = supabase.table('products').select('price').eq('sku', sku).execute()
        
        price_change = None
        previous_price = None
        price_changed_at = None
        
        if existing.data:
            old_price = existing.data[0].get('price')
            if old_price and product['price']:
                if float(old_price) != float(product['price']):
                    previous_price = old_price
                    price_change = float(product['price']) - float(old_price)
                    price_changed_at = datetime.now().isoformat()
                    
                    if price_change > 0:
                        print(f"      ğŸ“ˆ Fiyat arttÄ±: {old_price} â†’ {product['price']}")
                    else:
                        print(f"      ğŸ“‰ Fiyat dÃ¼ÅŸtÃ¼: {old_price} â†’ {product['price']}")
        
        # Kaydet
        data = {
            'sku': sku,
            'name': product['title'],
            'price': product['price'],
            'previous_price': previous_price,
            'price_change': price_change,
            'price_changed_at': price_changed_at,
            'stock_status': 'in_stock' if product['price'] else 'unknown',
            'url': product['url'],
            'product_name': product['title'],
            'product_url': product['url'],
            'stock_data': {
                'site': site_name,
                'currency': product['currency'],
                'scraped_at': datetime.now().isoformat()
            },
            'scraped_at': datetime.now().isoformat(),
            'updated_at': datetime.now().isoformat()
        }
        
        supabase.table('products').upsert(data, on_conflict='sku').execute()
        return True
        
    except Exception as e:
        print(f"      âŒ DB hatasÄ±: {str(e)[:50]}")
        return False

def main():
    print("\n" + "="*70)
    print("ğŸš€ ÃœRÃœN SCRAPER v4.0")
    print("="*70)
    
    # TÃœM URL'leri Ã§ek
    urls = get_all_urls()
    
    if not urls:
        print("\nâš ï¸ HiÃ§ URL bulunamadÄ±!")
        return
    
    print(f"\nğŸ“Š {len(urls)} URL scrape edilecek")
    print("â”€"*70)
    
    stats = {'success': 0, 'failed': 0, 'no_price': 0}
    
    for i, record in enumerate(urls, 1):
        url = record['url']
        site_name = record.get('anawebsite', '')
        
        # Config al
        config = get_site_config(url)
        
        print(f"[{i}/{len(urls)}] {config['name'][:20]:20s}", end=" ")
        
        # Scrape et
        product = scrape_url(url, config)
        
        if product:
            if product['price']:
                # Fiyat var - kaydet
                if save_to_db(product, config['name']):
                    print(f"ğŸ’¾ {product['title'][:30]:30s} - {product['price']} {product['currency']}")
                    stats['success'] += 1
                else:
                    print(f"âš ï¸ KayÄ±t baÅŸarÄ±sÄ±z")
                    stats['failed'] += 1
            else:
                # Fiyat yok
                print(f"âŒ {product['title'][:30]:30s} - Fiyat yok")
                stats['no_price'] += 1
        else:
            # Scrape baÅŸarÄ±sÄ±z
            print(f"âœ— Scrape baÅŸarÄ±sÄ±z")
            stats['failed'] += 1
        
        # Rate limiting
        if i % 10 == 0:
            time.sleep(1)
        else:
            time.sleep(0.3)
    
    # Ã–zet
    print("\n" + "="*70)
    print("ğŸ“Š Ã–ZET")
    print("="*70)
    print(f"Toplam URL: {len(urls)}")
    print(f"âœ… BaÅŸarÄ±lÄ±: {stats['success']}")
    print(f"âŒ Fiyat yok: {stats['no_price']}")
    print(f"âœ— Hata: {stats['failed']}")
    print("="*70 + "\n")

if __name__ == "__main__":
    main()
